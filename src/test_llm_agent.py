"""
Test script for LLM Agent with updated configuration
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Load environment variables from .env automatically
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸  python-dotenv chÆ°a Ä‘Æ°á»£c cÃ i. Äá»ƒ tá»± Ä‘á»™ng load .env, hÃ£y cháº¡y: pip install python-dotenv")

from llm_agent import GeminiLLMAgent, AnalysisRequest, AnalysisType

def test_llm_agent():
    """Test LLM Agent with real data"""
    
    # Sample clusters from the actual data
    sample_clusters = {
        0: ["engineer", "developer", "cloud", "development", "application", "design", "microservices", "scalable"],
        1: ["skill", "backend", "kubernetes", "deployment", "learning data"],
        2: ["tensorflow", "testing", "javascripttypescript", "computing", "looking", "deep", "model", "tensorflow pytorch"],
        3: ["preferred", "certification", "rest", "sql"],
        4: ["learning", "must", "senior", "apis", "scikitlearn"],
        5: ["react", "frontend", "frontend react", "build"],
        6: ["network"],
        7: ["rest apis"],
        8: ["python", "python scripting", "docker", "panda", "year"],
        9: ["data", "required", "scripting", "deep learning", "knowledge", "pytorch"]
    }
    
    print("ğŸ§ª Testing LLM Agent with updated configuration")
    print("=" * 60)
    
    try:
        # Initialize agent
        print("ğŸ¤– Initializing GeminiLLMAgent...")
        agent = GeminiLLMAgent()
        
        # Create analysis request
        request = AnalysisRequest(
            clusters=sample_clusters,
            analysis_type=AnalysisType.SKILL_GROUPING,
            context="PhÃ¢n tÃ­ch loáº¡i: trend_analysis",
            max_tokens=2000,
            temperature=0.3
        )
        
        # Perform analysis
        print("ğŸ“Š Performing skill grouping analysis...")
        result = agent.analyze(request)
        
        print("\nâœ… Analysis completed successfully!")
        print(f"   ğŸ“‹ Type: {result.analysis_type}")
        print(f"   ğŸ¯ Confidence: {result.confidence_score:.2f}")
        print(f"   ğŸ“ Summary: {result.summary[:200]}...")
        print(f"   ğŸ“ˆ Trends found: {len(result.trends)}")
        print(f"   ğŸ’¡ Recommendations: {len(result.recommendations)}")
        
        # Show detailed analysis keys
        print(f"   ğŸ” Analysis details: {list(result.detailed_analysis.keys())}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error during LLM Agent test: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_llm_agent()
    if success:
        print("\nğŸ‰ LLM Agent test completed successfully!")
    else:
        print("\nğŸ’¥ LLM Agent test failed!")
